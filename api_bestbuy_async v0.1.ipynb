{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import asyncio\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from time import perf_counter, sleep\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import quote_plus\n",
    "from azure.cosmos import exceptions, CosmosClient, PartitionKey\n",
    "\n",
    "import config_bestbuy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def api_bestbuy_test(page=1, api_index=0, page_size=100, last_update_date=None):\n",
    "    key = config_bestbuy.bestbuy_api_key\n",
    "    apis = ['products', 'categories', 'stores', f'products(itemUpdateDate>{last_update_date}&active=*)']\n",
    "    url = f\"https://api.bestbuy.com/v1/{apis[api_index]}\"\n",
    "    payload = {\n",
    "        'apiKey': key, \n",
    "        'pageSize': page_size, \n",
    "        'format': 'json', \n",
    "        'show': 'all', \n",
    "        'page': page\n",
    "        }\n",
    "    r = requests.get(f'{url}', params=payload)\n",
    "\n",
    "    await asyncio.sleep(.2)\n",
    "    print(r.json()['currentPage'])\n",
    "    return r\n",
    "\n",
    "\n",
    "async def main():\n",
    "    page = 0\n",
    "    api_index = 0\n",
    "    page_size = 100\n",
    "    last_update_date = None\n",
    "    pg = 1\n",
    "    pages = await api_bestbuy_test(page=1, api_index=0, page_size=100, last_update_date=None)\n",
    "    print(pages.json()['totalPages'])\n",
    "    # r = await api_bestbuy_test(pg=1, api_index=0, page_size=100, last_update_date=None)\n",
    "    # tasks = [api_bestbuy_test(page=page+1, api_index=api_index, page_size=page_size, last_update_date=last_update_date) for page in range(pages)]\n",
    "    tasks = [\n",
    "        api_bestbuy_test(page=1, api_index=api_index, page_size=page_size, last_update_date=last_update_date),\n",
    "        api_bestbuy_test(page=2, api_index=api_index, page_size=page_size, last_update_date=last_update_date)\n",
    "    ]\n",
    "    r = await asyncio.gather(*tasks)\n",
    "    print(r)\n",
    "    # print(tasks)\n",
    "    # await api_bestbuy_test(page=0, api_index=api_index, page_size=page_size, last_update_date=last_update_date)\n",
    "    # api_bestbuy_test(pg=1, api_index=0, page_size=100, last_update_date=None)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def to_matrix(x, n):\n",
    "    l = []\n",
    "    for i in range(x):\n",
    "        l.append(i+1)\n",
    "    return [l[i:i+n] for i in range(0, len(l), n)]\n",
    "\n",
    "\n",
    "async def ceiling_division(n, d):\n",
    "    return -(n // -d)\n",
    "\n",
    "\n",
    "async def initialize(folder_index=0):\n",
    "\n",
    "    folders = ['products', 'categories', 'stores', 'products_update']\n",
    "    datename = datetime.utcnow().strftime('%Y%m%d')\n",
    "    cosmos_endpoint = config_bestbuy.bestbuy_cosmosdb_end_point\n",
    "    cosmos_primary_key = config_bestbuy.bestbuy_cosmosdb_primary_key\n",
    "    client = CosmosClient(cosmos_endpoint, cosmos_primary_key)\n",
    "    db_name = 'BestBuyDB'\n",
    "    database = client.create_database_if_not_exists(id=db_name)\n",
    "    container_name = 'Products'\n",
    "    container = database.create_container_if_not_exists(\n",
    "        id=container_name,\n",
    "        partition_key=PartitionKey(path='/department'),\n",
    "        offer_throughput=400\n",
    "    )\n",
    "    path = config_bestbuy.path\n",
    "    foldername = f'best_buy_{datename}\\\\{folders[folder_index]}'\n",
    "    folderpath = os.path.join(path, foldername)\n",
    "\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "\n",
    "    db = os.path.join(config_bestbuy.path, 'bestbuy.db')\n",
    "    conn_string = f'sqlite:///{db}'\n",
    "    engine = create_engine(conn_string)\n",
    "\n",
    "    # params = quote_plus(config_bestbuy.bestbuy_sql_odbc_string)\n",
    "    # engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "\n",
    "    with engine.connect() as cnx:\n",
    "        try:\n",
    "            sel_stmt = \"SELECT * FROM products LIMIT 0\"\n",
    "            df_db = pd.read_sql(sql=sel_stmt, con=cnx)\n",
    "            db_cols = df_db.columns.tolist()\n",
    "\n",
    "            last_update_stmt = 'SELECT MAX(itemUpdateDate) FROM products'\n",
    "            df_itemUpdateDate = pd.read_sql(sql=last_update_stmt, con=cnx)\n",
    "            last_update_date = df_itemUpdateDate.iloc[0, 0]\n",
    "            \n",
    "        except Exception as e:\n",
    "            db_cols = []\n",
    "            last_update_date = None\n",
    "            \n",
    "    return folderpath, datename, engine, db_cols, last_update_date, container\n",
    "\n",
    "\n",
    "def insert_db(r, engine, db_cols, container, cursor_mark):\n",
    "\n",
    "    cols = ['nextCursorMark', 'total', 'totalPages', 'queryTime', 'totalTime', 'canonicalUrl', \n",
    "            'sku', 'name', 'type', 'startDate', 'new', 'activeUpdateDate', 'active', 'regularPrice', \n",
    "            'salePrice', 'clearance', 'onSale', 'categoryPath', 'customerReviewCount', 'customerReviewAverage', \n",
    "            'priceUpdateDate', 'itemUpdateDate', 'class', 'classId', 'subclass', 'subclassId', 'department', 'departmentId', \n",
    "            'theatricalReleaseDate', 'studio', 'manufacturer', 'modelNumber', 'condition', 'artistName', 'images', 'image', 'color']\n",
    "    bool_cols = [\"new\", \"active\", \"clearance\", \"onSale\"]\n",
    "    int_cols = [\"total\", \"totalPages\"]\n",
    "    float_cols = [\"queryTime\", \"totalTime\", \"regularPrice\", \"salePrice\", \"customerReviewCount\", \"customerReviewAverage\", 'theatricalReleaseDate']\n",
    "    date_cols = [\"startDate\", \"activeUpdateDate\", \"priceUpdateDate\", \"itemUpdateDate\"]\n",
    "    \n",
    "    with engine.connect() as cnx:\n",
    "        io = r.json()\n",
    "        # for product in io['products']:\n",
    "        #     product['cursorMark'] = cursor_mark\n",
    "        #     product['id'] = str(uuid.uuid4())\n",
    "        #     container.create_item(body=product)\n",
    "        \n",
    "        df_meta = pd.DataFrame(io)\n",
    "        df_meta = df_meta.iloc[:, :-1]\n",
    "        df_products = pd.DataFrame(io['products'])\n",
    "        df = df_meta.merge(df_products, how='inner', left_index=True, right_index=True)\n",
    "        df = df.loc[:, cols]\n",
    "        df.insert(0, 'request_timestamp', datetime.utcnow())\n",
    "\n",
    "        for col in df.columns.tolist():\n",
    "            if col in bool_cols:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('bool')\n",
    "            elif col in int_cols:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('int64')\n",
    "            elif col in float_cols:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('float64')\n",
    "            elif col in date_cols:\n",
    "                df.loc[:, col] = pd.to_datetime(df.loc[:, col], errors='coerce', infer_datetime_format=True)\n",
    "            else:\n",
    "                df.loc[:, col] = df.loc[:, col].astype('str')\n",
    "                \n",
    "        df.to_sql(name='products', con=cnx, if_exists='append', index=False)\n",
    "\n",
    "\n",
    "async def api_bestbuy(datename, folderpath, page=1, api_index=0, page_size=100, last_update_date=None):\n",
    "    key = config_bestbuy.bestbuy_api_key\n",
    "    apis = ['products', 'categories', 'stores', f'products(itemUpdateDate>{last_update_date}&active=*)']\n",
    "    url = f\"https://api.bestbuy.com/v1/{apis[api_index]}\"\n",
    "    payload = {\n",
    "        'apiKey': key, \n",
    "        'pageSize': page_size, \n",
    "        'format': 'json', \n",
    "        'show': 'all',\n",
    "        'page': page\n",
    "        }\n",
    "\n",
    "    delay = page/5\n",
    "    t0 = perf_counter()\n",
    "    await asyncio.sleep(delay)\n",
    "    t1 = perf_counter()\n",
    "    r = requests.get(f'{url}', params=payload)\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        \n",
    "        pg = r.json()['currentPage']\n",
    "        filename = f'best_buy_{datename}_{pg:05}.json'\n",
    "        filepath = os.path.join(folderpath, filename)\n",
    "\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(r.json(), f, indent=4)\n",
    "\n",
    "        # insert_db(r=r, engine=engine, db_cols=db_cols, container=container, cursor_mark=nextcursorMark)\n",
    "    \n",
    "    print(f'{pg=}', f'{delay=}', f'{t1-t0=}', sep=' | ')\n",
    "    return r\n",
    "\n",
    "\n",
    "async def main(api_index=0, page_size=100):\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    folderpath, datename, engine, db_cols, last_update_date, container = await initialize(folder_index=api_index)\n",
    "    \n",
    "    try:\n",
    "        pages = await api_bestbuy(datename=datename, folderpath=folderpath, api_index=api_index, page_size=page_size, last_update_date=last_update_date)\n",
    "        pages = pages.json()['totalPages']\n",
    "        print(pages)  \n",
    "        batches = to_matrix(pages, 5)\n",
    "        tasks = [api_bestbuy(datename=datename, folderpath=folderpath, page=page+1, api_index=api_index, page_size=page_size, last_update_date=last_update_date) for page in range(pages)]\n",
    "        await asyncio.gather(*tasks)\n",
    "        # r = await api_bestbuy(page=pg, api_index=api_index, page_size=page_size, last_update_date=last_update_date)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    print(f'fin: {perf_counter()-t0=}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # [0: 'products', 1: 'categories', 2: 'stores', 3: f'products(itemUpdateDate>{last_update_date}&active=*)']\n",
    "    await main(api_index=0, page_size=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tip: To query for updates or deltas since you last walked through the result set you can use the itemUpdateDate attribute. To ensure that your query results include changes to a productâ€™s active/inactive status, add active=* to your query parameters. \n",
    "For example: .../v1/products(itemUpdateDate>2017-02-06T16:00:00&active=*)?format=json&pageSize=100&cursorMark=*&apiKey=YOUR_API_KEY\n",
    "For example: .../v1/products(itemUpdateDate>today&active=*)?format=json&pageSize=100&cursorMark=*&apiKey=YOUR_API_KEY\n",
    "\"https://api.bestbuy.com/v1/products(releaseDate>today)?format=json&show=sku,name,salePrice&apiKey=YourAPIKey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Page = 1\n",
    "api_index = 0\n",
    "page_size = 100\n",
    "\n",
    "r = api_bestbuy_test(pg=Page, api_index=api_index, page_size=page_size)\n",
    "io = r.json()\n",
    "io['id'] = str(uuid.uuid4())\n",
    "io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['nextCursorMark', 'total', 'totalPages', 'queryTime', 'totalTime', 'canonicalUrl', 'sku', 'name', 'type', 'startDate', 'new', 'activeUpdateDate', 'active', 'regularPrice', 'salePrice', 'clearance', 'onSale', 'categoryPath', 'customerReviewCount', 'customerReviewAverage', 'priceUpdateDate', 'itemUpdateDate', 'class', 'classId', 'subclass', 'subclassId', 'department', 'departmentId', 'images', 'image', 'color']\n",
    "io = r.json()\n",
    "df_meta = pd.DataFrame(io)\n",
    "df_meta = df_meta.iloc[:, :-1]\n",
    "df_products = pd.DataFrame(io['products'])\n",
    "df = df_meta.merge(df_products, how='inner', left_index=True, right_index=True)\n",
    "df = df.loc[:, cols]\n",
    "df.insert(0, 'request_timestamp', datetime.utcnow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalpages = set()\n",
    "for _ in range(io['totalPages']):\n",
    "    totalpages.add(_+1)\n",
    "\n",
    "totalpages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_bestbuy.bestbuy_sql_odbc_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db = os.path.join(config_bestbuy.path, 'bestbuy.db')\n",
    "conn_string = f'sqlite:///{db}'\n",
    "engine = create_engine(conn_string)\n",
    "\n",
    "# params = quote_plus(config_bestbuy.bestbuy_sql_odbc_string)\n",
    "# engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "    \n",
    "with engine.connect() as cnx:\n",
    "    df_test = pd.read_sql(sql=\"select color from products_archive\", con=cnx)\n",
    "\n",
    "for col in df_test.columns.tolist():\n",
    "    print(col, df_test.loc[:, col].astype('str').apply(len).max(), sep= ' - ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(x, n):\n",
    "    l = []\n",
    "    for i in range(x):\n",
    "        l.append(i+1)\n",
    "    return [{_: l[i:i+n]} for _, i in enumerate(range(0, len(l), n))]\n",
    "\n",
    "\n",
    "batches = to_matrix(2244, 5)\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    print(batch.get(i), \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.utcnow().date()\n",
    "n_days = datetime.utcnow().date() - timedelta(days=2)\n",
    "n_hours = (today-n_days)/timedelta(seconds=1)\n",
    "n_hours"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3410afedb74081d81603511028deadddc25ba0f01c14e0cb891e2c2473f81884"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
